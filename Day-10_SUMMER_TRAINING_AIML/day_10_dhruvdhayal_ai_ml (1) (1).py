# -*- coding: utf-8 -*-
"""Day_10_DHRUVDHAYAL_AI_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QVcJ8kjWk4PaZH5U-OTCnL01SJkcZAQu

#CNN in Neural Networking.

--> Convolution.
"""

#Importing the Inbuilt Libraries.
from tensorflow import keras;
import numpy as np;
import matplotlib.pyplot as plt;
import matplotlib.image as mimg;

(Xtrain,ytrain),(Xtest,ytest) = keras.datasets.mnist.load_data();
print(Xtrain.shape,ytrain.shape);
print(Xtest.shape,ytest.shape);

#Now, we need to creaate the CNN Model.
cnn_model=keras.models.Sequential(); #Empty Framwork.

#Making the Convolutional Layer-1.
cnn_model.add(keras.layers.Conv2D(10,3,activation='relu',input_shape=(28,28,1)));
#MaxPooling-1.
cnn_model.add(keras.layers.MaxPool2D(pool_size=(2,2)));

#Making the Convolutional Layer-2.
cnn_model.add(keras.layers.Conv2D(50,3,activation='relu'));
#MaxPooling-2.
cnn_model.add(keras.layers.MaxPool2D(pool_size=(2,2)));

#Feed Forwards Network.
#Input Layer.
cnn_model.add(keras.layers.Flatten());  # Input Layers.
#Hidden Layers.
cnn_model.add(keras.layers.Dense(200,activation='relu')); #HL1
cnn_model.add(keras.layers.Dense(200,activation='relu')); #HL2
cnn_model.add(keras.layers.Dense(200,activation='relu')); #HL3
#Output Layer.
cnn_model.add(keras.layers.Dense(10,activation='softmax'));

#Now, we can simply create the value of the Optimizer.
#OPTIMIZER.
loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True);
cnn_model.compile(optimizer='sgd',loss=loss,metrics=['accuracy']);
cnn_model.summary();

#Now, we need to train the cnn model along with the Validation Data.
#Now, we need to train the cnn model along with the Validation Data.
history=cnn_model.fit(Xtrain, ytrain, epochs=20, validation_data=(Xtest,ytest)); # Pass ytrain as a separate argument

import matplotlib.pyplot as plt

plt.figure(1,(4,4))
plt.plot(history.epoch,history.history['accuracy'],label='TrainAccuracy')
plt.plot(history.epoch,history.history['val_accuracy'],label='TestAccuracy')
plt.title('Train and validation accuracy comparisons')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.figure(2,(4,4))
plt.plot(history.epoch,history.history['loss'],label='TrainLoss')
plt.plot(history.epoch,history.history['val_loss'],label='TestLoss')
plt.title('Train and validation loss comparison')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.legend()

"""#Now, Implementing on CIFAR100."""

#Importing the Inbuilt Libraries.
from tensorflow import keras;
import numpy as np;
import matplotlib.pyplot as plt;
import matplotlib.image as mimg;

(Xtrain,ytrain),(Xtest,ytest) = keras.datasets.cifar100.load_data(label_mode='fine');
print(Xtrain.shape,ytrain.shape);
print(Xtest.shape,ytest.shape);

# data scaling
Xtrain = Xtrain/ Xtrain.max()
Xtest = Xtest/ Xtest.max()
print(len(np.unique(ytrain)))

#Importing the Inbuilt Libraries.
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mimg

(Xtrain,ytrain),(Xtest,ytest) = keras.datasets.cifar100.load_data(label_mode='fine')
print(Xtrain.shape,ytrain.shape)
print(Xtest.shape,ytest.shape)

# data scaling
Xtrain = Xtrain/ Xtrain.max()
Xtest = Xtest/ Xtest.max()
print(len(np.unique(ytrain)))

#Now, we need to create the CNN Model.
cnn_model=keras.models.Sequential() #Empty Framwork.

#Making the Convolutional Layer-1.
cnn_model.add(keras.layers.Conv2D(10,3,activation='relu',input_shape=(32,32,3)))
#MaxPooling-1.
cnn_model.add(keras.layers.MaxPool2D(pool_size=(2,2)))

#Making the Convolutional Layer-2.
cnn_model.add(keras.layers.Conv2D(50,3,activation='relu'))
#MaxPooling-2.
cnn_model.add(keras.layers.MaxPool2D(pool_size=(2,2)));

#Making the Convolutional Layer-3.
cnn_model.add(keras.layers.Conv2D(50,3,activation='relu'))
#MaxPooling-2.
cnn_model.add(keras.layers.MaxPool2D(pool_size=(2,2)));

#Making the Convolutional Layer-4.
cnn_model.add(keras.layers.Conv2D(50,3,activation='relu'))
#MaxPooling-2.
cnn_model.add(keras.layers.MaxPool2D(pool_size=(2,2)))

#Feed Forwards Network.
#Input Layer.
cnn_model.add(keras.layers.Flatten())  # Input Layers.
#Hidden Layers.
cnn_model.add(keras.layers.Dense(200,activation='relu')) #HL1
cnn_model.add(keras.layers.Dense(200,activation='relu')) #HL2
cnn_model.add(keras.layers.Dense(200,activation='relu')) #HL3
#Output Layer.
cnn_model.add(keras.layers.Dense(100,activation='softmax')) # Update output layer to 100 classes for CIFAR-100

#Now, we can simply create the value of the Optimizer.
#OPTIMIZER.
loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False) # Set from_logits to False
cnn_model.compile(optimizer='sgd',loss=loss,metrics=['accuracy'])
cnn_model.summary()

#Now, we need to train the cnn model along with the Validation Data.
#Now, we need to train the cnn model along with the Validation Data.
history=cnn_model.fit(Xtrain, ytrain, epochs=100, validation_data=(Xtest,ytest))

import matplotlib.pyplot as plt

plt.figure(1,(4,4))
plt.plot(history.epoch,history.history['accuracy'],label='TrainAccuracy')
plt.plot(history.epoch,history.history['val_accuracy'],label='TestAccuracy')
plt.title('Train and validation accuracy comparisons')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.figure(2,(4,4))
plt.plot(history.epoch,history.history['loss'],label='TrainLoss')
plt.plot(history.epoch,history.history['val_loss'],label='TestLoss')
plt.title('Train and validation loss comparison')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.legend()

# evaluate the test data
[loss, acc] = cnn_model.evaluate(Xtest,ytest) # Change nn_model to cnn_model
print('Loss:', loss)
print("Testing Accuracy:",acc)

"""#Importing the Values and Train with the Help of the SVM."""

from google.colab import drive
drive.mount('/gdrive', force_remount=True);

from google.colab import drive
drive.mount('/content/drive')

!unzip '/content/drive/MyDrive/Colab Notebooks/Face_Recognizations/orl_face (2).zip' -d '/content/drive/MyDrive/Colab Notebooks/Face_Recognizations';

#Now, Importing the Images data from the unzip files.
import matplotlib.pyplot as plt
import matplotlib.image as mimg
import numpy as np
import pandas as pd

#Now, we need to read the values of the Data from a Drive.
user_name=24 #Labels.
samples_no=6 #Define the Variable Sample_Numbers.
# Added format specifiers for both user_name and samples_no
path='/content/drive/MyDrive/Colab Notebooks/Face_Recognizations/orl_face/u%d/%d.png'%(user_name,samples_no)

#Now, we need to read the data from images.
imag=mimg.imread(path)
print("\n 1. Type of the Image is: ",type(imag))
print("\n 2. Length of the Image is: ",imag.shape)
print("\n")

#Now, we need to plot the Image.
plt.figure(1,figsize=(5,10))
plt.imshow(imag,cmap='gray')
plt.axis("off")
plt.show()

#Now, convert 2-D Images it into 1-D Images by using the Flatten.
feat=imag.reshape(1,-1);
print("\n 1. Length of the Images: ",imag.shape);
print("\n 2. Length of the Features: ",feat.shape);
print("\n --> Range: ",imag.min()," - ",imag.max());

#Logic to acess all the samples of the User.
#Of the Valued Users.
total_sample=400;
user_name=26;
sample_no=6;
data=np.zeros((total_sample,imag.shape[0]*imag.shape[1]));
label=np.zeros((total_sample));
images=np.zeros((total_sample,imag.shape[0],imag.shape[1]));
index=-1;
for i in range(1,41,1):
  for j in range(1,11,1):
    index=index+1;
    #acess any of the single image.
    user_name=i;
    sample_no=j;
    # Added format specifiers %d for user_name and sample_no
    path='/content/drive/MyDrive/Colab Notebooks/Face_Recognizations/orl_face/u%d/%d.png'%(user_name,sample_no);
    #reading the Image.
    im=mimg.imread(path);
    data[index,:]=feat
    label[index]=i
    images[index,:,:]=im
    print("user num ",i,'samp no',j,'processed...');

#Now, displaying the values of the Image.
plt.imshow(images[397,:,:],cmap='gray');
plt.axis('off');
plt.show();

#Importing all the Built-in Libraries.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt # Import matplotlib.pyplot

#Now, we need to show all the (5*5) Matrix Values.
plt.figure(1,figsize=(10,10));
for i in range(5):
  for j in range(5):
    num=np.random.randint(0,400);
    samples=images[num,:,:];
    la=label[num];
    plt.subplot(5,5,i*5+j+1) # Use plt to access subplot
    plt.imshow(samples,cmap='gray');
    plt.axis('off');
    plt.title(" "+str(int(la)));
#showing the Image (5*5) Matrix.
plt.show();

from sklearn import svm
import pandas as pd
from sklearn import model_selection
from sklearn import metrics;
# Import train_test_split
X = data # Extract the data from the 'data' key
y =label # Use the target variable from the Iris dataset


# split the data into 70:30 ratio
Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=5) # Use train_test_split
print(Xtrain.shape,ytrain.shape)
print(Xtest.shape,ytest.shape)

ker = ['poly','linear','rbf']
c_value = [1,2,3]

# pre allocation of the result variable
result = np.zeros((len(ker),len(c_value)))
for i in range(len(ker)):
  for j in range(len(c_value)):
    # create the svm classifier
    orl_svm_model = svm.SVC(kernel=ker[i],gamma='scale',C=c_value[j])

    # train the model
    orl_svm_model = orl_svm_model.fit(Xtrain,ytrain)

    # predict the labels
    ypred = orl_svm_model.predict(Xtest)

    # accuracy
    acc = metrics.accuracy_score(ypred,ytest)
    #print("accuracy:", acc)
    result[i,j]=acc
print(result)

ResultDF = pd.DataFrame(result,index=ker,columns=["C=1","C=2","C=3"])
ResultDF
print("\n Showing in the form of the Graphical Methods!");
ResultDF.plot(kind='bar',figsize=(4,4));

print("\n");
print("\n --> SVM Accuracy is: ",acc);

"""#Neural Networking."""

import matplotlib.pyplot as plt;
import matplotlib.image as mimg;

path='/content/drive/MyDrive/Colab Notebooks/Face_Recognizations/orl_face/u1/1.png';
im=mimg.imread(path);
print(im[0,10]);
plt.imshow(im,cmap='gray');
plt.axis("off");
plt.show();

import numpy as np
data = np.zeros((410,112,92))
label = np.zeros(410)
print(data.shape)
count = 0
for i in range(1,42):
  for j in range(1,11):
    path = '/content/drive/MyDrive/Colab Notebooks/Face_Recognizations/orl_face/u1/1.png'.format(i, j, j) # Use .format() to insert i and j into the path
    im = mimg.imread(path)
    data[count,:,:] = im
    label[count] = i
    count+=1

print(data.shape,label.shape)

from sklearn import model_selection
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

xtrain,xtest,ytrain,ytest = model_selection.train_test_split(data,label,test_size=0.3)
print(xtrain.shape, ytrain.shape)
print(xtest.shape, ytest.shape)

face_model = keras.Sequential()
#input layer
face_model.add(keras.layers.Flatten(input_shape=(xtrain.shape[1],xtrain.shape[2])))

#hidden layers
face_model.add(keras.layers.Dense(128,activation='relu'))
face_model.add(keras.layers.Dense(256,activation='relu'))
face_model.add(keras.layers.Dense(256,activation='relu'))
face_model.add(keras.layers.Dense(512,activation='relu'))

#output layer
face_model.add(keras.layers.Dense(410,activation='relu'))

#add optimizer
face_model.compile(optimizer="SGD", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

print(face_model.summary())

#train the model
history = face_model.fit(xtrain, ytrain, epochs=150)

#evaluate the test data

[loss, accNN] = face_model.evaluate(xtest, ytest)
print(f"Testing Accuracy of Neural Network (NN) is: {accNN}")

"""#CNN

"""

# create the CNN model
cnn_model = keras.models.Sequential() # empty framework
# Convolutinal layer 1
cnn_model.add(keras.layers.Conv2D(64,3,activation='relu',input_shape=(112,92,1)))
cnn_model.add(keras.layers.Conv2D(64,3,activation='relu',input_shape=(112,92,1)))
cnn_model.add(keras.layers.Conv2D(64,3,activation='relu',input_shape=(112,92,1)))
# maxpooling -1
cnn_model.add(keras.layers.MaxPool2D((2,2)))

# Convolutinal layer 2
cnn_model.add(keras.layers.Conv2D(64,3,activation='relu'))
cnn_model.add(keras.layers.Conv2D(64,3,activation='relu'))
cnn_model.add(keras.layers.Conv2D(64,3,activation='relu'))
# maxpooling -2
cnn_model.add(keras.layers.MaxPool2D((2,2)))

# feed forwards network
cnn_model.add(keras.layers.Flatten()) # input layer
cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL1
cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL2
cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL3
cnn_model.add(keras.layers.Dense(410)) # Output layer

# optimizer
loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
cnn_model.compile(optimizer='sgd',loss = loss,metrics=['accuracy'])
cnn_model.summary()

# train the cnn along with the validation data
history = cnn_model.fit(xtrain,ytrain,epochs=20,validation_data=(xtest,ytest));

import matplotlib.pyplot as plt

plt.figure(1,(4,4))
plt.plot(history.epoch,history.history['accuracy'],label='TrainAccuracy')
plt.plot(history.epoch,history.history['val_accuracy'],label='TestAccuracy')
plt.title('Train and validation accuracy comparisons')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.figure(2,(4,4))
plt.plot(history.epoch,history.history['loss'],label='TrainLoss')
plt.plot(history.epoch,history.history['val_loss'],label='TestLoss')
plt.title('Train and validation loss comparison')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.legend()

# prompt: find the accuracy
# evaluate the test data
[loss, accCNN] = cnn_model.evaluate(xtest,ytest)
print('Loss:', loss)
print("Testing Accuracy of CNN:",accCNN)

# prompt: which one is better svm model, neural networks, cnn and plot the graph with therie accuracy

import matplotlib.pyplot as plt

# Assuming acc, accNN, and accCNN are the accuracies of SVM, NN, and CNN respectively.
accuracy_scores = [acc, accNN, accCNN]
model_names = ['SVM', 'Neural Network', 'CNN']

plt.bar(model_names, accuracy_scores)
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Accuracy Comparison of Different Models')
plt.ylim([0, 1])  # Set y-axis limits for better visualization
plt.show()

best_model_index = accuracy_scores.index(max(accuracy_scores))
print(f"\n -->The best model is {model_names[best_model_index]} with an accuracy of {accuracy_scores[best_model_index]}")

