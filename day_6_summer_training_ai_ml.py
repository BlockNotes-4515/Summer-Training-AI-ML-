# -*- coding: utf-8 -*-
"""Day-6_SUMMER_TRAINING_AI/ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16h9sgNkmqunMDhn4gUaxp9AqTYpekUgL

#Now, we are using the Day-5 Practice on Summer_Training_(AI/ML).
"""

#Now, we importing the values of the Libraries.
from sklearn import datasets; #Importing the datasets collection of data & Informations.
from sklearn import svm; #Used for the classifications.
from sklearn import metrics; #Used for the Measurment overall accuracy & Performance.
from sklearn import model_selection; #Used for splitting the data.

#Now, we simply have to load the values of the datasets.
data=datasets.load_digits();
print("\n 1. Type of the Data in datasets are given : ",type(data));

#Now, we need to describe the data loaded from datasets.
print(data.DESCR);

#Now, we need to set the values of the data & labels.

#X-values represents the values of the data in a datasets.
X=data.data;
print(X.shape);
print(type(X));

#Y-values represents the labels of the data in a datasets.
Y=data.target;
print(Y.shape);
print(type(Y));

#Now, we need to show the valued graph.
import matplotlib.pyplot as plt;
import matplotlib.image as mimg;
import numpy as np;

#Loading the values of the Images.
image=data.images;
y=data.target;
print("\n 1. Type of the Image form of the Representations: ",type(image));
print("\n 2, Total Collection of the Data has been given: ",image.data);
print("\n---------------------------------------------------------\n");
num=1270;
samples_im=image[num, :, :];
label=y[num];
plt.figure(1,figsize=(5,5));
plt.imshow(samples_im,cmap="gray");
plt.title("Label is : "+str(label));
plt.axis("off");
plt.show();

#Show the Values of the Graph form of Representations.
import matplotlib.pyplot as plt;
import matplotlib.image as impag;
import numpy as np;

#Show the Values of the Images by the Valued data.
image=data.images;
y=data.target;
print("\n 1. Type of the Data has been used to represent are: ",type(image));
print("\n 2. Total Collection of the Data has been given: ",image.data);
print("\n---------------------------------------------------------\n");
num=1270;
samples_im=image[num, :, :];
label=y[num];
plt.figure(1,figsize=(5,5));
plt.imshow(samples_im,cmap="gray");
plt.title(" Actual Target is: "+str(label));
plt.axis("off");
plt.show();

"""#Task-1: To represent the images in (7*7) Matrix from by random number."""

#Performing the values of the Task-1.
import matplotlib.pyplot as plt;
import matplotlib.image as impag;
import numpy as np;

#Now, we need to load the collection of data and informations.
image=data.images;
y=data.target;
print("\n 1. Type of the Data Represented in the form of the Image: ",type(image));
print("\n 2. Collection of the Data in the Image Availables are: ",image.data);
for i in range(49):
  num=np.random.randint(0,1270);
  samples_im=image[num,:,:];
  label=y[num];
  plt.figure(1,(8,6));
  plt.subplot(7,7,i+1);
  plt.imshow(samples_im,cmap="gray");
  #plt.title(" Actual Target is: "+str(label));
  plt.axis("off");

#Show the graph final plotting.
plt.title(" TASK-1 ");
plt.show();

"""#Task-2: Now, generate the no's in the image Representation in the Ascending Order."""

#Performing the Values of the Task-2.
import matplotlib.pyplot as plt
import matplotlib.image as impag
import numpy as np

#Showing the valued of the images.
image = data.images
y = data.target
print("\n 1. Type of the Data in graph Representations: ",type(image))
print("\n 2. Total Collection of the Data has been given: ",image.data)

#For generating the values of ascending order.
for i in range(10):
  # Find indices of images with label 'i'
  indices = np.where(y == i)[0]
  for j, idx in enumerate(indices[:10]): # Plot up to 10 images for each label
      samples_im = image[idx,:,:]
      label = y[idx]
      plt.figure(1,(8,8))
      plt.subplot(10,10,i*10 + j + 1) # Calculate subplot index correctly
      plt.imshow(samples_im,cmap="gray")
      #plt.title(" Actual Target is: "+str(label))
      plt.axis("off")

#Showing the valued graph form are given below!
plt.show()

#Now, we load the datasets.
#We, also describe the datasets.
#We, also perform the task to represent the data of datasets in image forms.
#Now, we need to split the data in training and testing.
#Examples 70:30 '70->Training and 30->Testing used to split the values of the data in two forms training and testing.

ratio=0.3;
Xtest,Xtrain,ytest,ytrain=model_selection.train_test_split(X,y,test_size=ratio,random_state=7);
print("\n 1. Testing Data are: ",Xtest.shape,ytest.shape);
print("\n 2. Training Data are: ",Xtrain.shape,ytrain.shape);

#Now, we need to train the values of the Model.
clff_model=svm.SVC();

#Classification of the Model in training and testing Phases.
clff_model=clff_model.fit(Xtrain,ytrain);

#Now, mention the label in the testing phase and then, classify the values model.
ypred=clff_model.predict(Xtest);

print("\n 1. Prediction Values: ",ypred);
print("\n 2. Actual Values: ",ytrain);
print("\n---------------------------------------------------------\n");
print("\n 3. Predicted Values: ",ypred.shape);
print("\n 4. Actual Values: ",ytrain.shape);

#Now, model is trained and test succesfully.
#Now, we need to calculate the overall performance.

accu=metrics.accuracy_score(ypred,ytest);
confu_matrix=metrics.confusion_matrix(ypred,ytest);
report=metrics.classification_report(ypred,ytest);

print("\n 1. Accuracy of the Model Digit Datasets are: ",accu);
print("\n---------------------------------------------------------\n");

print("\n 2. Confusion Matrix of the Model Digit Datasets are: \n\n",confu_matrix);
print("\n---------------------------------------------------------\n");

print("\n 3. Classification Report of the Model Digit Datasets are: \n\n",report);
print("\n---------------------------------------------------------\n");

"""#Showing the Values of the Confusion Matrix."""

import seaborn as sns;
sns.heatmap(confu_matrix,annot=True,cmap="jet");
plt.title("Confusion Matrix on Digits Datasets!");

#Showing the graph images by proper plotting.
plt.axis("on");
plt.show();

"""#Task-3: Perform the Following task based on the given Guidlines.

--> Load, the Iris DataSets.

--> Understand the Data from it's DESCR.

--> Split the data in the Ratio of 60:40 and 70:30 Ratio.

--> Now, classify the Data.

--> Measure the Accuracy, Precision, Recall and F1-Score.

--> Show the Data values for each split.

@NOTE: F1-score is the "HARMONI - MEAN" which is compined value of "Precision" & "Recall" to reduce complexity and helps to compare training and testing of the data during under the processing.
"""

# 1. Loading the Iris Datasets.
from sklearn import datasets;
from sklearn import svm;
from sklearn import metrics;
from sklearn import model_selection;

#Loading the Valuable Datasets.
data=datasets.load_iris();
print("\n 1. Type of the Data in datasets are given : ",type(data));

# 2. Understanding the Data from it's DESCR. by giving the proper Descriptions.
print(data.DESCR);

# 3. #Now, we splitting the data of 60:40 and 70:30 ratio's, in Training and Testing Phases.

ratio=0.3;
Xtest,Xtrain,ytest,ytrain=model_selection.train_test_split(X,y,test_size=ratio,random_state=7);
print("\n 1. Testing Data are: ",Xtest.shape,ytest.shape);
print("\n 2. Training Data are: ",Xtrain.shape,ytrain.shape);

# 4. Classification of the Model means Training and Testing properly.

clff_model=svm.SVC();

#Now, we need to train the model are given below!
clff_model=clff_model.fit(Xtrain,ytrain);

#Now, specifying the Labels in the Testing phase.
ypred=clff_model.predict(Xtest);

#Printing all the values actual label and predicted label classification comparisons.
print("\n 1. Predicted Values: ",ypred.shape);
print("\n 2. Actual Label: ",ytrain.shape);
print("\n---------------------------------------------------------\n");

#Now, we need to calculate the values of accuracy, performance, precision , recall, and f1-score.

acc=metrics.accuracy_score(ypred,ytest);

confu_matrix=metrics.confusion_matrix(ypred,ytest);

report=metrics.classification_report(ypred,ytest);

preci=metrics.precision_score(ypred,ytest,average="macro");

reca=metrics.recall_score(ypred,ytest,average="macro");

f1=metrics.f1_score(ypred,ytest,average="macro");

print("\n---------------------------------------------------------\n");

print("\n 1. Accuracy of the Iris datasets: ",acc);
print("\n----------------------------------------------------------\n");

print("\n 2. Confusion Matric Matrix of Iris: \n\n",confu_matrix);
print("\n----------------------------------------------------------\n");

print("\n 3. Classification Report of Iris: \n\n",report);
print("\n----------------------------------------------------------\n");

print("\n 4. Precision Values: ",preci);
print("\n----------------------------------------------------------\n");

print("\n 5. Recall Values: ",reca);
print("\n----------------------------------------------------------\n");

print("\n 6. F1-Score Values: ",f1);
print("\n----------------------------------------------------------\n");

# load the iris dataset
# understand the datset from its DESCR
# and implement the 60:40 and 70:30 ratio train test split
# and compare its acc, precision, recall and f1_score
# for each split

from sklearn import metrics,datasets,model_selection,svm
data = datasets.load_iris()

X = data.data
y = data.target
Result = np.zeros((2,4))
ratio= [0.4,0.3]
for i in range(len(ratio)):
  Xtrain,Xtest,ytrain,ytest = model_selection.train_test_split(X,y,test_size=ratio[i],random_state=5)
  # create the model
  clf_model = svm.SVC()
  # train the model
  clf_model = clf_model.fit(Xtrain,ytrain)
  # test the model
  ypred = clf_model.predict(Xtest)

  # accuracy
  temp_acc = metrics.accuracy_score(ypred,ytest)
  # precision
  temp_pre = metrics.precision_score(ypred,ytest,average='macro')
  # recall
  temp_rec = metrics.recall_score(ypred,ytest,average='macro')
  # f1 score
  temp_f1 = metrics.f1_score(ypred,ytest,average='macro')

  list_result = [temp_acc,temp_pre,temp_rec,temp_f1]
  Result[i,:]=list_result

print(Result)
res = ['Accuracy','Precision','Recall','F1_score']

import pandas as pd
res_df = pd.DataFrame(Result,columns=res,index=['60:40','70:30'])
print(res_df)

res_df.T.plot(kind = 'bar')

"""#(SVM)-"SUPPORT VECTOR MACHINES."
"""

#Using different kernal functionalities based on it1
from sklearn import datasets;
from sklearn import svm;
from sklearn import metrics;
from sklearn import model_selection;

#Loading the Values of the DataSets.
data=datasets.load_iris();
print("\n 1. Type of the Data in datasets are given : ",type(data));

#Now, we need to describe the values of the Data.
print(data.DESCR);

#Now, we need to split the values of the data like: 70:30 and 60:40.
#Now, we need split datasets in Training and Testing Phases.

ratio=0.3;
Xtest,Xtrain,ytest,ytrain=model_selection.train_test_split(X,y,test_size=ratio,random_state=7);
print("\n 1. Testing Data are: ",Xtest.shape,ytest.shape);
print("\n 2. Training Data are: ",Xtrain.shape,ytrain.shape);

#Now, we need to classify the given models.
#Classification of the model in order to train them.

clff_model=svm.SVC(kernel="linear", gamma="auto",C=2);

#Now, we have to train the model in classifying Manner.
clff_model=clff_model.fit(Xtrain,ytrain);

#Predicting the predicted label from actual label in testin phase.
ypred=clff_model.predict(Xtest);

#Printing the actual label and predicted label.
print("\n 1. Predicted Values: ",ypred.shape);
print("\n 2. Actual Label: ",ytrain.shape);
print("\n---------------------------------------------------------\n");

#Measuring the values by showing it's performance.

acc=metrics.accuracy_score(ypred,ytest);

confu_matrix=metrics.confusion_matrix(ypred,ytest);

report=metrics.classification_report(ypred,ytest);

print("\n 1. Accuracy: ",acc);
print("\n---------------------------------------------------------\n");

print("\n 2. Confusion Matrix: \n\n",confu_matrix);
print("\n----------------------------------------------------------\n");

print("\n 3. Classification Report: \n\n",report);
print("\n----------------------------------------------------------\n");

"""#Task-1: Train the Model in Testing and Training , predict classify them and then analyse the data in a proper manner.
--> NOTE: Use, the "DIABETES" DataSets.
"""

import numpy as np;
import seaborn as sns;
import matplotlib.pyplot as plt;
import matplotlib.image as impag;

path='/content/diabetes.csv';
data=pd.read_csv(path);

print("\n --> Total Sixe of the Given Data are: ",data.shape);
print("\n---------------------------------------------------------\n");

print("\n ---------------> Given Values of the Data given from files: \n\n",data);
print("\n---------------------------------------------------------\n");

#Now, we need to define the values.
x=data.drop('Outcome',axis=1,inplace=False);
y=data['Outcome'];

#Now, we need to split the data in training and testing phase.
ratio=0.3;
Xtrain,Xtest,ytrain,ytest=model_selection.train_test_split(X,y,test_size=ratio,random_state=7);
print("\n 1. Testing Data: ",Xtrain.shape," ",ytrain.shape);
print("\n 2. Training Data: ",Xtest.shape," ",ytest.shape);

#Now, classifying the Valued Model.
#Classification based on trained them.

clff_model=svm.SVC(kernel='poly',gamma='scale',C=1);

#Trainee the Model.
clff_model=clff_model.fit(Xtrain,ytrain);

#Predict the Model by indicating their Labels.
ypred=clff_model.predict(Xtest);

#Printing the actual label and predicted label.
print("\n 1. Predicted Values: ",ypred.shape);
print("\n 2. Actual Label: ",ytrain.shape);
print("\n---------------------------------------------------------\n");

#Now, finding the values based on it's Performance.

acc=metrics.accuracy_score(ypred,ytest);

confu_matrix=metrics.confusion_matrix(ypred,ytest);

report=metrics.classification_report(ypred,ytest);

#Printing the Main Values.
print("\n 1. Total Accuracy: ",acc);
print("\n---------------------------------------------------------\n");

print("\n 2. Confusion Matrix: \n\n",confu_matrix);
print("\n---------------------------------------------------------\n");

print("\n 3. Classification Report: \n\n",report);
print("\n---------------------------------------------------------\n");

"""#Analuse the Data Given Below!"""

#Perform the 'EDA' on the Diabetes Datasets.
#Exploratory the Data Analysis.

import matplotlib.pyplot as plt;
import matplotlib.image as impag;
import numpy as np;
import pandas as pd;
import seaborn as sns;

#Now, we are plotting the graph for the classifications.
plt.figure(figsize=(15, 10))
for i, col in enumerate(data.columns):
  plt.subplot(3, 3, i + 1)
  sns.histplot(data[col])
  plt.subplots_adjust(wspace=0.5, hspace=0.5) # Adjust values as needed
  plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()
print("\n")

# Correlation matrix
corr_matrix = data.corr()
plt.figure(figsize=(8, 5))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

# Pairplot
sns.pairplot(data, hue='Outcome')
plt.show()

#To, show how many of them have the deficiency of Insulin who have injected with Glucose.
sns.scatterplot(data=data,x='Glucose',y='Insulin',hue='Outcome');
plt.show();

#Comparison Between the Diabetes and Non-Diabetes Patients.
sns.countplot(data=data,x='Outcome');
plt.show();

#Now, we need to show and analyze the data by using the box-plot.
plt.figure(1,figsize=(15,6));
plt.title("Box-Plot Representation of Patients Reports");
sns.boxplot(data=data,width=0.5,fliersize=5);
plt.tight_layout();
plt.show();

"""#Now, we need to show the age-wise Diabetes."""

#To, showing the Age-wise Diabets.
plt.figure(1,figsize=(15,6));
plt.title("Age Variation In Diabetic Patients")
sns.scatterplot(data=data,x='Age',y='BloodPressure');
#plt.tight_plot();
plt.show();

#counting the Maximum and Minimum Ages.
plt.figure(1,figsize=(15,6));
sns.countplot(data=data,x='Age');
plt.title("Counting of Ages in File CSV1");
#plt.tight_layout();
plt.show();

#Calculating the Maximum and Minimum Ages Group having the Diabetes.
print("\n 1. Maximum Ages in the Group: ",max(data['Age']));
print("\n 2. Minimum Ages in the Group: ",min(data['Age']));

#Showing the Scatterplot age of person who have diabetes or not based comparison on 'Outcome'.
plt.figure(1,figsize=(15,6));
sns.scatterplot(data=data,x='Age',y='BloodPressure',hue='Outcome');
plt.title("Age-wise Diabetes");
#plt.tight_layout(); can be used , refrence given only for the 'OPTIONAL' Based!
plt.show();

#Showing the Scatterplot age of person who have diabetes or not based comparison on 'Outcome'.
plt.figure(1,figsize=(15,6));
sns.violinplot(data=data,x='Age',y='BloodPressure',hue='Outcome');
plt.title("Age-wise Diabetes");
plt.tight_layout(); #Can be used , refrence given only for the 'OPTIONAL' Based!
plt.show();

#Showing the Scatterplot age of person who have diabetes or not based comparison on 'Outcome'.
plt.figure(1,figsize=(15,6));
sns.barplot(data=data,x='Age',y='BloodPressure',hue='Outcome',errorbar=None);
plt.title("Age-wise Diabetes");
#plt.tight_layout(); can be used , refrence given only for the 'OPTIONAL' Based!
plt.show();

"""#Task-4: We, need to add the Column called as 'Age_Category'!
--> If, Age<=30 shows 'Young'.

--> If, Age>=31 and Age<=45 shows 'Middle_Age'.

--> If, Age>=46 and Age<=65 shows 'Mature_Age'.

--> If, Age>=65 shows 'Old_Age'.
"""

#Now, we are performing the task in this prompts.
#Using the values of the Functions.

def age_category(age):
  if(age<=30):
    return("Young");
  elif(age>=31 and age<=45):
    return("Middle_Age");
  elif(age>=46 and age<=65):
    return("Mature_Age");
  else:
    return("Old_Age");

#Passing the Values in the Enumerate values Functions.
data['Age_Category']=data['Age'].apply(age_category);
print(data.head);

#Now, we also plotting the Values of the Graph.
plt.figure(1,figsize=(15,6));
sns.countplot(data=data,x='Age_Category',hue='Outcome');
plt.show();

"""#Task-5: Perform and train the Model by using the SVM.
#(SVM)-"SUPPORT VECTOR MACHINES."
"""

from sklearn import datasets;
from sklearn import svm;
from sklearn import metrics;
from sklearn import model_selection;

#Importing the Inbuilt Libraries.
import numpy as np;
import pandas as pd;
import seaborn as sns;
import matplotlib.pyplot as plt;
import matplotlib.image as impag;

#Loading the main Datasets.
path='/content/diabetes.csv';
data=pd.read_csv(path);

print("\n 1. Total Length of the Data in a Particular files: ",data.shape);
print("\n-----------------------------------------------------------------\n");

print("\n 2. Complete Data values exist in a Datasets files: ",data);
print("\n-----------------------------------------------------------------\n");

#Now, indicating the values in order to been read.
x=data.drop('Outcome',axis=1,inplace=False);
y=data['Outcome'];

#Now, we need to split the data in the training and testing phases.

ratio=0.3;
Xtrain,Xtest,ytrain,ytest=model_selection.train_test_split(X,y,test_size=ratio,random_state=7);
print("\n 1. Training Data: ",Xtrain.shape,ytrain.shape);
print("\n 2. Testing Data: ",Xtest.shape,ytest.shape);

#Now, classifying the Model based on it!
clff_model=svm.SVC(kernel='linear',gamma='scale',C=2); # Changed 'Linear' to 'linear'

#Training the Model to properly Trained Based.
clff_model=clff_model.fit(Xtrain,ytrain);

#Predicting the model and locate the labels in the Testing Phases.
ypred=clff_model.predict(Xtest);

#Printing all the Values of Comparison. with predicted with actual labels.
print("\n 1. Predicted Values: ",ypred.shape);
print("\n 2. Actual Label: ",ytrain.shape);
print("\n-----------------------------------------------------------------\n");

#Now, we need to find the values of the Performance.

acc=metrics.accuracy_score(ypred,ytest);

confu_matrix=metrics.confusion_matrix(ypred,ytest);

report=metrics.classification_report(ypred,ytest);

#Printing the Values.
print("\n 1. Accuracy of the Diabetes Datasets: ",acc);
print("\n-----------------------------------------------------------------\n");

print("\n 2. Confusion Matrix of Diabetes: \n\n",confu_matrix);
print("\n-----------------------------------------------------------------\n");

print("\n 3. Classification Report of Diabetes: \n\n",report);
print("\n-----------------------------------------------------------------\n");

"""#Task-6: We, need to show all the values of RBF, Linear, and Polynomial on different Penalty Parameter like: [ C1 , C2 , C3 ]."""

import pandas as pd;
import numpy as np;
import seaborn as sns;
import matplotlib.pyplot as plt;
import matplotlib.image as impag;

#Loading the data from the datasets.
path='/content/diabetes.csv';
data=pd.read_csv(path);

#Showing the Total Length of the Data.
print("\n 1. Length of the Data: ",data.shape);
print("\n-----------------------------------------------------------------\n");

print("\n 2. Showing the Values of Complete Information available in the CSV files: ",data);
print("\n-----------------------------------------------------------------\n");

#We, have to describe the values of the data.
print(data.describe())
# Use the describe method to get a summary of your DataFrame

#Now, we need import the data from the main 'Diabetes' CSV . File.
x=data.drop('Outcome',axis=1,inplace=False);
y=data['Outcome'];

#Now, we Split the data in the Training and Testing Phases.

ratio=0.3;
Xtrain,Xtest,ytrain,ytest=model_selection.train_test_split(X,y,test_size=ratio,random_state=7);
print("\n 1. Training Data: ",Xtrain.shape,ytrain.shape);
print("\n 2. Testing Data: ",Xtest.shape,ytest.shape);

#Now, we need to classify the model based on it!
#Proper Classifications of this Models are Given Below!

kernel=['rbf','linear','poly']; # Changed to lowercase
c_value=[1,2,3];

#Pre-Reallocation of the Result Variables.
result=np.zeros((len(kernel),len(c_value)));
for i in range(len(kernel)):
  for j in range(len(c_value)):
    clff_model=svm.SVC(kernel=kernel[i],gamma='scale',C=c_value[j]);
    clff_model=clff_model.fit(Xtrain,ytrain);
    ypred=clff_model.predict(Xtest);
    #Calculating the Values of the Accuracy.
    acc=metrics.accuracy_score(ypred,ytest);
    result[i,j]=acc;
print(result);
ResultDF = pd.DataFrame(result,index=kernel,columns=["C=1","C=2","C=3"]) # Use kernel here, not ker

ResultDF = pd.DataFrame(result,index=kernel,columns=["C=1","C=2","C=3"])
ResultDF = ResultDF.T
print(ResultDF)
ResultDF.plot(kind='bar',figsize=(4,4))

"""#Now, we are Importing another file and perform similar task for analysis and practice to complete SVM.
#--> Last Part of 'SVM'-"SUPPORT VECTOR MACHINE".
"""

#Importing all the Inbuilt Libraries.
from sklearn import datasets;
from sklearn import svm;
from sklearn import metrics;
from sklearn import model_selection;

#Importing pre-defined libraries.
import numpy as np;
import pandas as pd;
import seaborn as sns;
import matplotlib.pyplot as plt;
import matplotlib.image as impag;

#Loading the data from the fish CSV.Files.
path='/content/Fish.csv';
data=pd.read_csv(path);

#Show the Data inside the main CSV.Files.
print("\n 1. Total Length of the Data: ",data.shape);
print("\n-----------------------------------------------------------------\n");

print("\n 2. Complete Data values exist in a Datasets files: \n\n",data);
print("\n-----------------------------------------------------------------\n");

#We, need to describe the data in the fish.csv files.
print(data.describe());

#Now, we need to import the valued Data from the main files.
X=data.drop('Species',axis=1,inplace=False);
Y=data['Species'];

#Now, we need to split the data in training and testing.

ratio=0.3;
Xtrain,Xtest,ytrain,ytest=model_selection.train_test_split(X,y,test_size=ratio,random_state=7);
print("\n 1. Training Data: ",Xtrain.shape,ytrain.shape);
print("\n 2. Testing Data: ",Xtest.shape,ytest.shape);

#Now, we need to classigy the model by a proper classifications

kernel=['rbf','linear','poly']; # Changed 'RBF' to 'rbf', 'Linear' to 'linear', 'Poly' to 'poly'
c1_value=[1,2,3];
result=np.zeros((len(kernel),len(c1_value)));
for i in range(len(kernel)):
  for j in range(len(c1_value)):
    clff_model=svm.SVC(kernel=kernel[i],gamma='scale',C=c1_value[j]);
    clff_model=clff_model.fit(Xtrain,ytrain,);
    ypred=clff_model.predict(Xtest);
    #Calculating the Values of the Accuracy.
    acc=metrics.accuracy_score(ypred,ytest);
    result[i,j]=acc;
print(result);
print("\n");
ResultDF = pd.DataFrame(result,index=kernel,columns=["C=1","C=2","C=3"])
ResultDF = ResultDF.T;
print(ResultDF);
ResultDF.plot(kind='bar',figsize=(4,4));

"""#Now, we need to classify the values of the Fishes - Data."""

# Distribution of each feature in a subplot
plt.figure(figsize=(15, 10))
for i, col in enumerate(data.columns):
  plt.subplot(3, 3, i + 1)
  sns.histplot(data[col])
  plt.subplots_adjust(wspace=0.5, hspace=0.5) # Adjust values as needed
  plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()
print("\n")

#Showing all the species it in the scatterplot.
# Distribution of each feature in a subplot
plt.figure(figsize=(15, 10))
for i, col in enumerate(data.columns):
  plt.subplot(3, 3, i + 1)
  sns.scatterplot(data[col])
  plt.subplots_adjust(wspace=0.5, hspace=0.5) # Adjust values as needed
  plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()
print("\n")

# Distribution of each feature in a subplot
plt.figure(figsize=(15, 10))
for i, col in enumerate(data.columns):
  plt.subplot(3, 3, i + 1)
  sns.histplot(data[col])
  plt.subplots_adjust(wspace=0.5, hspace=0.5) # Adjust values as needed
  plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()
print("\n")

ResultDF = pd.DataFrame(result,index=kernel,columns=["C=1","C=2","C=3"]);
#plt.figure(1,figsize=(13,6));
ResultDF = ResultDF.T
print(ResultDF)
ResultDF.plot(kind='bar',figsize=(8,6))

"""#Result: We, Found that best Method is 'Linear' Methods."""

# Aggregate data (replace 'category_column' with your actual column)
category_counts = data['Species'].value_counts()

# Plot pie chart
plt.figure(figsize=(8, 8))
plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=90)
plt.title('Distribution of Categories');
#plt.tight_plot();
plt.show()

ResultDF = pd.DataFrame(result,index=kernel,columns=["C=1","C=2","C=3"]);
#plt.figure(1,figsize=(13,6));
ResultDF = ResultDF.T
print(ResultDF)
ResultDF.plot(kind='bar',figsize=(8,6))

"""#Here, is the Complete Practice Set of Both Day-5&6 Mainly Day-6 Completion."""