# -*- coding: utf-8 -*-
"""Day-8_DHRUVDHAYAL_AI/ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hQ3PNDHas4YZg-6aF_Z46b05I7GHvi9b

#K-Means Classifications.
"""

#Now, we need to initialise the inbuilt Libraries.
from sklearn import datasets;
from sklearn import svm;
from sklearn import metrics;
from sklearn import model_selection;
from sklearn import cluster;
import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;

#Now,we need to train the model by using the Sklearn.
#Now, we generate the random data for Experimentation in order to gain new Experience.

data=np.random.randint(0,100,(500,2));
print("\n 1. Total Size of the Data: ",data.shape);
#print("\n 2. Description of the Data: ",data);

#Now, we need to show the data, visualization of the Data.
plt.figure(1,figsize=(4,4));
plt.scatter(data[:,0],data[:,1]);
plt.title("Raw Data");
plt.xlabel("");
plt.ylabel("");
plt.show();

#Experimenting the K-Means Unsupervised Machine learning Model.
#To, Segment the 2-D Model.
#Creating, the K-Means Model.

#Proper Classification of the Model Step-by-Steps.
km_model=cluster.KMeans(n_clusters=4,random_state=5);

#Now, Train the Dummy Data Model as Trained Model.
km_model=km_model.fit(data);

#No, prediction possible in the testing case.
print(km_model.cluster_centers_);
print("\n 1. Lenngth of the Labels: ",len(km_model.labels_));
#print(km_model.label_);
print("\n 2. Center of the Coordinates: ",km_model.cluster_centers_[0][0]);

#Visualise the Dummy Data.
plt.figure(1,figsize=(8,4));
plt.subplot(1,2,1);
plt.scatter(data[:,0],data[:,1]);
plt.title("Raw Data");
plt.xlabel("X-Axes");
plt.ylabel("Y-axes");

#Now, showing the another graphical methods based on trained datasets model.
plt.subplot(1,2,2);
plt.scatter(data[:,0],data[:,1],c=km_model.labels_);
plt.title("K-Means Classification");
for i in range(len(km_model.cluster_centers_)):
  dx=km_model.cluster_centers_[i][0];
  dy=km_model.cluster_centers_[i][1];
  plt.plot(dx,dy,"kd");

#Show and plot the actual values of the Graph.
plt.show();

"""#Elbow Methods."""

#Using the Elbow Methods.
#Elbow Methods: Defined that sum of the Squared Distances altogether to find out the minimum distances over multiple Iterations, if after several iterations it can't reduce the distance then we will stop the process at the end it means we get the actual real optimal values.
dist=[];
k_value=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15];
for i in range(len(k_value)):
  km_model=cluster.KMeans(n_clusters=k_value[i],random_state=5);
  #Train the Actual Trained Model.
  km_model=km_model.fit(data);
  #Now, update the data in the lists.
  dist.append(km_model.inertia_);

#Visualise the data by plotting and showing the Graph of 'Elbow Methods'.
#Visualising the Actual Data Values.
plt.figure(1,figsize=(5,5));
plt.plot(k_value,dist,'--kd');
plt.title("Elbow Methods");
plt.xlabel("Node ID Values");
plt.ylabel("Sum of the Squared Distances");
plt.grid("on");
plt.show();

"""#Practising Set of K-Means Set Algorithms."""

#Inialising all the Inbuilt Libraries of the DataModels.
from sklearn import datasets;
from sklearn import svm;
from sklearn import metrics;
from sklearn import model_selection;
from sklearn import cluster;

#Another Common Inbuilt Libraries.
import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;

#Train the Model by using the Sklearn.
#Now, Load the DummyDatasets.
data=np.random.randint(1,100,(500,2));
print("\n 1. Total Size of the Data: ",data.shape);
#print("\n 2. Descriptions of the Data: ",data);

#Now, we need to visualise the Data Models.
plt.figure(1,figsize=(4,4));
plt.scatter(data[:,0],data[:,1]);
plt.title("Raw Data");
plt.xlabel("X-Axes");
plt.ylabel("Y-Axes");
plt.show();

#Now, we need to train the Model, to become training datasets.
#Proper Classifications of the Data.

km_model=cluster.KMeans(n_clusters=4,random_state=5);

#Train the Model to become the Trained Model K-Means Clusterring.
km_model=km_model.fit(data);

#No, Data available regarding Testing no prediction Possibles.
print("\n 1. Center Cluster of the K-Means: \n\n",km_model.cluster_centers_);
print("\n 2. Total Length of the Labels are: ",len(km_model.labels_));
#print(km_model.labels_);
print("\n 3. Accurate Precision Values of the Center Coordinates: ",km_model.cluster_centers_[0][0]);

#Visualise the Data by plotting and showing the Graphical Chart.
plt.figure(1,figsize=(8,4));
plt.subplot(1,2,1);
plt.scatter(data[:,0],data[:,1]);
plt.title("Raw Data");
plt.xlabel("X-Axes");
plt.ylabel("Y-Axes");

#Now, Shoeing the Actual K-Means Clusttering Classifications with 4-centroids it quite flexible you can also change the value from 4-5 to ~  !
plt.subplot(1,2,2);
plt.scatter(data[:,0],data[:,1],c=km_model.labels_);
plt.title("K-Means Classifications");
for i in range(len(km_model.cluster_centers_)):
  dx=km_model.cluster_centers_[i][0];
  dy=km_model.cluster_centers_[i][1];
  plt.plot(dx,dy,"kd");
plt.show();

"""#Applying the Methods called as Elbow Methods."""

#Applying the main concepts of the Elbow Methods.
#Using the Inertia: sum of all the Squared Distances.
dist=[];
k_values=[1,2,34,5,6,7,8,9,10,11,12,13,14,15];
for i in range(len(k_values)):
  km_model=cluster.KMeans(n_clusters=k_values[i],random_state=5);
  #Train the Model in proper Manner.
  km_model=km_model.fit(data);
  #Now, we need to append the distance lists by using the inertia.
  dist.append(km_model.inertia_);

#Now, we need to Visualise the Values of the Data.
plt.figure(1,figsize=(5,5));
plt.plot(k_values,dist,'--ko');
plt.title("Elbow Methods");
plt.xlabel("Node ID Values");
plt.ylabel("Sum of the Squared Distances");
plt.grid("on");
plt.show();

"""#Mall_Customers."""

#Importing all the values of the Libraries.
from sklearn import datasets;
from sklearn import svm;
from sklearn import metrics;
from sklearn import model_selection;
from sklearn import cluster;

#Importing the Another Common Libraries.
import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;

#Importing the Data Values.
path='/content/Mall_Customers.csv';
data=pd.read_csv(path);

#Now, Showing the Values of the Collection of Data & Informatio present it in the CSV Files.
print("\n 1. Total Length of the Data Files are: ",data.shape);
print("\n--------------------------------------------------------");
print("\n 2. Complete Description of the Table-Datasets: \n\n",data);
print("\n--------------------------------------------------------");

#Now, we need to show the infomation about the data.
print(data.info());

#Now, we need to describe the values of the csv file.
print(data.describe());

#Now, we need to show the values of the Elbow Methods.
#By, using it with the Inertia.
#We, take only the 2-inputs one as a 'Annual Income (k$)' & 'Spending Score (1-100)'
#First we have to specify and extract the data columns with information from the CSV Files.
import matplotlib.pyplot as plt;
dx=data['Annual Income (k$)'];
dy=data['Spending Score (1-100)'];
plt.figure(1,figsize=(5,5));
plt.scatter(dx,dy);
plt.title("Raw Data");
plt.xlabel("Annual Income (k$)");
plt.ylabel("Spending Score (1-100)");

#Creating an Array with the Numerical Python Array called as 'NumPyArray'.
numarray1=np.array((dx,dy)).T;
print("\n 1. --> Total Length of an Array: ",numarray1.shape);
print("\n");
plt.show();

#Now, we have to show the values of the Trained the Model.
#Proper Classifications of the Model.

km_model=cluster.KMeans(n_clusters=4,random_state=5);

#Train the Model with the given dx,dy values.
km_model=km_model.fit(numarray1);

#No, predictions Possible now, we hve to show up all values.
print("\n 1. Center of the Coordinates: \n\n",km_model.cluster_centers_);
print("\n 2. Total Length of the Labels: ",len(km_model.labels_));
#print(km_model.labels_);
print("\n 3. Accurate Precision Values of the Center Coordinates: ",km_model.cluster_centers_[0][0]);

#Now, Visualise the Data Values based on dx,dy values.
plt.figure(1,figsize=(8,4));
plt.subplot(1,2,1);
plt.scatter(numarray1[:,0],numarray1[:,1]);
plt.title("Raw Data");

#Now, we have to show cluster with their Coordinates.
plt.subplot(1,2,2);
plt.scatter(numarray1[:,0],numarray1[:,1],c=km_model.labels_);
plt.title("K-Means Classifications");
for i in range(len(km_model.cluster_centers_)):
  dx=km_model.cluster_centers_[i][0];
  dy=km_model.cluster_centers_[i][1];
  plt.plot(dx,dy,"kd");
plt.show();

#Now, we need to use 'Elbow Methods'.
#Now, we are using the inertia_ -Methods.
dist=[];
k_value=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15];
for i in range(len(k_value)): # Iterate over the correct range
  km_model=cluster.KMeans(n_clusters=k_value[i],random_state=5);
  #Now, we have to train the model based on csv file data-extracted-columns.
  km_model=km_model.fit(numarray1);
  #Now, we need to append it in the distance empty lists.
  dist.append(km_model.inertia_);

#Visualise the Data and show by the valued graphical forms.
plt.figure(1,figsize=(5,5));
plt.plot(k_value,dist,'--kd');
plt.title("Elbow Methods");
plt.xlabel("Node ID Values");
plt.ylabel("Sum of the Squared Distances");
plt.grid("on");
plt.show();

"""#Image Recognigations!"""

#Now, we are using the image Recognizations.
#Firstly, we have to take the data read and then show the valued Image.
#Importing all the Inbuilt Libraries.
import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;
import matplotlib.image as mimg;

#Read and take the data from the folder in google colab.
path='/content/sunflower.jpg';
data=mimg.imread(path);
print("\n 1. Total Length of the Data: ",data.shape);
print("\n");

#Now, we have to show the image by the proper visualisatios.
plt.figure(1,figsize=(5,5,));
plt.imshow(data);
plt.title("Raw Data");
plt.axis("off");
plt.grid("off");
plt.show();

#Show the Image by using the cv2 libraries which shows the actual representation of the given Images.
import cv2;
newimg=cv2.resize(data,(200,200));
print("\n --> Total Length of the new-image: ",newimg.shape);
print("\n");

#Visualise the pic of the new-image.
plt.figure(1,figsize=(5,5));
plt.imshow(newimg);
plt.title("CV2 Image Representations");
plt.axis("off");
plt.grid("off");

#Plot and show the valiued Grphical forms.
plt.show();

#Figure out the colors in the picture of different color variations with the help of Pathches.
from google.colab.patches import cv2_imshow;

#Now, we have to configure the color in a Image.
red=newimg[:,:,0];  #For, the First Componenet.
green=newimg[:,:,1]; #For, the Second Component.
blue=newimg[:,:,2]; #For, the Third Component.

#Visualise the Image by showing the different color variations.
cv2_imshow(red);
cv2_imshow(green);
cv2_imshow(blue);

#Creating the three newImages Array (numpyArray)!
#Having the uint-8 (Unsigned 8-bit Integer forms)!

rim=np.zeros((newimg.shape[0],newimg.shape[1],newimg.shape[2]),dtype='uint8');
gim=np.zeros((newimg.shape[0],newimg.shape[1],newimg.shape[2]),dtype='uint8');
bim=np.zeros((newimg.shape[0],newimg.shape[1],newimg.shape[2]),dtype='uint8');
print(rim.shape);
#for checing the values.
#now, we need to replace up with the previous components.

# 1. Replace the rim component up with the red componenet.
rim[:,:,0]=red;
# 2. Replace the gim component up with the green componenet.
gim[:,:,1]=green;
# 3. Replace the bim component up with the blue componenet.
bim[:,:,2]=blue;

#Visulaise and show the given resulting values.
cv2_imshow(rim);
cv2_imshow(gim);
cv2_imshow(bim);

"""#As, you can see I print all the value in the form of 'rgb' form but it follows by default methods called as a 'bgr' !

--> NOTE: Each, image have the maximum dimensional Range upto (0-255).
"""

#Now, showing each of the maximum and minimum range of the 'Each and Ecery Component' values.
print("(",rim.max()," - ",rim.min(),")");
print("(",gim.max()," - ",gim.min(),")");
print("(",bim.max()," - ",bim.min(),")");

"""#Facial Recognizations.

-->We, uses 'VOILAJONE' Algorithm which helps to detect any object in the Image Easily!
"""

#How, to detect the faces in the image.
# 1. We, need to detect the Complete Image.
# 2. We, need to detect the total_no. of Faces in the Image.
# 3. Seperate it out.
# NOTE: We, use the 'VoilaJones' Methods Algorithm easlity detect the object in the given Image.

!pip install opencv-python;

#Import the inbuilt libraries.
import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;
import matplotlib.image as mimg;
import cv2;

#Now, we have to read the image.
path='/content/family.webp';
data=mimg.imread(path);
print("\n --> Total Length of the Data: ",data.shape);
print("\n");
#Now, we have to resize by using the cv2.
im_new=cv2.resize(data,(512,512));
#cv2.imshow("Multi faces image", im) # Replace with cv2_imshow if needed.

# covert the color (BGR) into grayscale
gray_im = cv2.cvtColor(im_new,cv2.COLOR_BGR2GRAY)
print("Resolution of the gray image")
print(gray_im.shape)
#cv2.imshow("Multi faces image", gray_im) # Replace with cv2_imshow if needed

path = "/content/haarcascade_frontalface_default (1).xml";
# face detector
face_detector = cv2.CascadeClassifier(path);

# run your classifier on the image
faces = face_detector.detectMultiScale(gray_im,scaleFactor=1.1,minNeighbors=1,minSize=(60,60))
print(faces)

# diaply the bounding box on all the faces
for var in range(len(faces)):
    dx = faces[var][0]
    dy = faces[var][1]
    w = faces[var][2]
    h = faces[var][3]
    cv2.rectangle(im_new, (dx,dy),(dx+w,dy+h),(255,0,0),2)

cv2_imshow(im_new) # Use cv2_imshow instead of cv2.imshow

#Import the inbuilt libraries.
import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;
import matplotlib.image as mimg;
import cv2;

#Now, we have to read the image.
path='/content/family.webp';
data=mimg.imread(path);
print("\n --> Total Length of the Data: ",data.shape);
print("\n");
#Now, we have to resize by using the cv2.
im_new=cv2.resize(data,(512,512));
#cv2.imshow("Multi faces image", im) # Replace with cv2_imshow if needed.

# convert the color (BGR) into grayscale
gray_im = cv2.cvtColor(im_new,cv2.COLOR_BGR2GRAY)
print("Resolution of the gray image")
print(gray_im.shape)
#cv2.imshow("Multi faces image", gray_im) # Replace with cv2_imshow if needed

path = "/content/haarcascade_frontalface_default (1).xml";
# face detector
face_detector = cv2.CascadeClassifier(path);

# run your classifier on the image
faces = face_detector.detectMultiScale(gray_im,scaleFactor=1.1,minNeighbors=1,minSize=(60,60))
print(faces)

# display the bounding box on all the faces
for var in range(len(faces)):
    dx = faces[var][0]
    dy = faces[var][1]
    w = faces[var][2]
    h = faces[var][3]
    cv2.rectangle(im_new, (dx,dy),(dx+w,dy+h),(255,0,0),2)

cv2_imshow(im_new) # Use cv2_imshow instead of cv2.imshow

# !pip install opencv-python

# read the image
import cv2
import numpy as np
import matplotlib.pyplot as plt

path = '/content/family.webp';
im = cv2.imread(path)
im_new = cv2.resize(im, (512,512))
print("Resolution of the image")
print(im.shape)
#cv2.imshow("Multi faces image", im)

# covert the color (BGR) into grayscale
gray_im = cv2.cvtColor(im_new,cv2.COLOR_BGR2GRAY)
print("Resolution of the gray image")
print(gray_im.shape)
#cv2.imshow("Multi faces image", gray_im)


path = "/content/haarcascade_frontalface_default (1).xml";
# face detector
face_detector = cv2.CascadeClassifier(path)

# run your classifier on the image
faces = face_detector.detectMultiScale(gray_im,scaleFactor=1.1,minNeighbors=10)
print(faces)
all_faces=[]
# diaply the bounding box on all the faces
for var in range(len(faces)):
    dx = faces[var][0]
    dy = faces[var][1]
    w = faces[var][2]
    h = faces[var][3]
    cv2.rectangle(im_new, (dx,dy),(dx+w,dy+h),(255,0,0),2)
    # seperate out the faces
    croppedFace = gray_im[dy:dy+h,dx:dx+w]
    all_faces.append([croppedFace])
    print(croppedFace.shape)
print(len(all_faces))

for i in range(len(all_faces)):
    f = np.array(all_faces[i])[0,:,:]
    newF = cv2.resize(f, (112,92))
    print(newF.shape)
    plt.figure(i+1)
    plt.imshow(f,cmap='gray')
    plt.title('Detected face')
    plt.axis('off')

#cv2.imshow("face detected",im_new)
#cv2.waitKey(0)
#cv2.destroyAllWindows()

"""#Camera Image Recognizations."""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import time

cam = cv2.VideoCapture(0); # Access the default camera
path = "/content/haarcascade_frontalface_default (1).xml";
# face detector
face_detector = cv2.CascadeClassifier(path);

frame=True
while(frame==True):
    val,im = cam.read()
    if not val: # Check if a frame was successfully read
        print("Frame could not be read. Exiting...")
        break
    im_new = cv2.resize(im, (512,512))
    # covert the color (BGR) into grayscale
    gray_im = cv2.cvtColor(im_new,cv2.COLOR_BGR2GRAY)
    # run your classifier on the image
    faces = face_detector.detectMultiScale(gray_im,scaleFactor=1.1,minNeighbors=10)

    # disply the bounding box on all the faces
    for var in range(len(faces)):
        dx = faces[var][0]
        dy = faces[var][1]
        w = faces[var][2]
        h = faces[var][3]
        cv2.rectangle(im_new, (dx,dy),(dx+w,dy+h),(255,0,0),2)
    cv2.imshow('camera live feed', im_new)
    # desired button of your choice
    if cv2.waitKey(1) & 0xFF == ord('q'):
        frame=False
        break


cam.release()
cv2.destroyAllWindows()